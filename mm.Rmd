
```{r}
pSheet_final <- read.csv("molly_composite.csv", header = TRUE)
```

```{r}
# Get median PU for each camp
medianPU <- pSheet_final %>%
  group_by(Camp) %>%
  summarize(medianPU = median(PU, na.rm = TRUE))

# CASE 1: C determines U

pu_c = medianPU$medianPU[medianPU$Camp == "Concerned"]
puc_c = 1 - 1e-15
pc_c = pu_c

pu_s = medianPU$medianPU[medianPU$Camp == "Skeptical"]
puc_s = 1 - 1e-15
pc_s = pu_s

VoI_log_s = VoI_log(pu_s, puc_s, pc_s)
VoI_log_c = VoI_log(pu_c, puc_c, pc_c)

# (check)
punotc_s = punotc(pc_s, puc_s, pu_s)
punotc_c = punotc(pc_c, puc_c, pu_c)

VoD_log_gmod_max = VoD_log_gmod(pu_s, pu_c, puc_s, puc_c, pc_s, pc_c, punotc(pc_s, puc_s, pu_s), punotc(pc_c, puc_c, pu_c))

# CASE 2: ~C determines U

puc_c = 1e-15
pc_c = 1 - pu_c

puc_s = 1e-15
pc_s = 1 - pu_s

VoI_log_c = VoI_log(pu_c, puc_c, pc_c)
VoI_log_s = VoI_log(pu_s, puc_s, pc_s)

# (check)
punotc_s = punotc(pc_s, puc_s, pu_s)
punotc_c = punotc(pc_c, puc_c, pu_c)

VoD_log_gmod_max = VoD_log_gmod(pu_s, pu_c, puc_s, puc_c, pc_s, pc_c, punotc(pc_s, puc_s, pu_s), punotc(pc_c, puc_c, pu_c))
```

```{r}
library(tidyr)
library(dplyr)
setwd("~/fri/voi-vod")
source("sources/functions.R")
library(ggplot2)
library(xpt)

library(ggplot2)
library(scales)

```

```{r}
VoD_log_gmod_easy <- function(dt, id1, id2) {
  pu_a <- dt[dt$person == id1, "PU"] %>% pull
  pu_b <- dt[dt$person == id2, "PU"] %>% pull
  puc_a <- dt[dt$person == id1, "PUc"] %>% pull
  puc_b <- dt[dt$person == id2, "PUc"] %>% pull
  pc_a <- dt[dt$person == id1, "Pc"] %>% pull
  pc_b <- dt[dt$person == id2, "Pc"] %>% pull
  punotc_a <- dt[dt$person == id1, "punotc"] %>% pull
  punotc_b <- dt[dt$person == id2, "punotc"] %>% pull

  answer <- VoD_log_gmod(pu_a, pu_b, puc_a, puc_b, pc_a, pc_b, punotc_a, punotc_b)
  return(answer)
}
```

```{r}
# How many rows are there in each ID-Person combo?
alpha <- pSheet_final %>%
  group_by(ID, Person) %>%
  summarise(n = n()) %>%
  arrange(desc(n))
```

```{r}
summaryResults_final <- pSheet_final %>%
    # Own beliefs only (drop reciprocal questions & VOD)
    select(-c(starts_with("S_"), starts_with("E_"), contains("VoD"), "X"))
```

```{r}
if (FALSE) {  # This was for conditional tree data (pSheet_final_supers.csv)
  # Reshape this so that each row is a question-person pair. Question is the ID, person is the letters before the first underscore

  reshapedData <- summaryResults_final %>%
    pivot_longer(cols = -ID, names_to = "variable", values_to = "value")

  # separate person from other variables
  reshapedData <- reshapedData %>%
    separate(variable, into = c("person", "measure"), sep = "_", extra = "merge") %>%
    pivot_wider(names_from = measure, values_from = value)

  # view reshaped data
  head(reshapedData)
}

reshapedData <- pSheet_final %>%
  rename(person = Person)
```

```{r}
# Aliases
newnames <- read.csv("aliases.csv", header = TRUE)
reshapedData <- merge(reshapedData, newnames, by.x = "person", by.y = "name", all.x = TRUE)
# Drop "person" and rename alias to "person"
reshapedData <- reshapedData %>%
  select(-person) %>%
  rename(person = alias)
```

```{r}
# Add log VoI (KL Divergence) now if it's P8 data
reshapedData <- reshapedData %>%
  rowwise() %>%
  mutate(punotc = punotc(Pc, PUc, PU))
```

```{r}
# For rows with incoherent forecasts, make PU NA (we'll drop these)
reshapedData <- reshapedData %>%
  mutate(PU = ifelse(PUc * Pc > PU, NA, PU))
```

```{r}
reshapedData <- reshapedData %>%
  mutate(VoI_log = VoI_log(PU, PUc, Pc, punotc)) %>%
  mutate(VoI_naive = VoI_naive(PU, PUc, Pc, punotc)) %>%
  mutate(person = paste0(person, " (", Camp, ")"))
```

```{r}
# Why are there still NaN's in VoI_log? NA's are when they didn't answer the question (fine), but NaN's are perplexing
inconsistent <- reshapedData %>%
  filter(is.nan(VoI_log) | is.na(PU)) %>%
  select(person, Camp, ID, PU, Pc, PUc, punotc, VoI_log) %>%
  arrange(ID)

write.csv(inconsistent, "inconsistent.csv", row.names = FALSE)

claireWarning <- reshapedData %>%
  filter(grepl("Claire", person), grepl("Warning shot", ID))

claireWarning %>%
  rowwise() %>%
  mutate(punotc = punotc(Pc, PUc, PU)) %>%
  mutate(VoI_log = VoI_log(PU, PUc, Pc, punotc)) %>%
  mutate(VoI_naive = VoI_naive(PU, PUc, Pc, punotc))
```

```{r}
reshapedData <- reshapedData %>%
  filter(!is.na(PU)) %>%  # cases where P(c) * P(U|c) > P(U) OR either P(c) or P(U|c) were NA
  filter(!is.nan(VoI_log))
```

```{r}
quantile50 <- function(x) {
  return(quantile(x, p = 0.5, type = 1))
}

bresults <- reshapedData %>%
  group_by(Camp, ID) %>%
  summarize(median = quantile(VoI_log, p = 0.5, type = 1, na.rm = TRUE),
            x = list(boot_results(VoI_log, statistic = "quantile50"))) %>%
  unnest(x)
```

```{r}
# Arrange by median for Camp "A"
ordering <- bresults %>%
  filter(Camp == "Concerned") %>%
  arrange(median) %>%
  pull(ID)

bresults$ID <- factor(bresults$ID, levels = ordering)

possum <- ggplot(bresults, aes(x = ID, y = median, group = Camp)) +
  geom_point(aes(color = Camp)) +  # To show medians as points colored by Camp
  geom_errorbar(aes(ymin = confint_lower, ymax = confint_upper, color = Camp, alpha = 0.5)) +
  scale_y_continuous(trans = log10_trans(),
                    breaks = trans_breaks("log10", function(x) 10^x),
                    labels = trans_format("log10", math_format(10^.x))) +
  labs(title = "Median VOI with Bootstrapped CIs",
       y = "Log VOI",
       x = "Question") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

ggsave("possum_concerned.png", width = 12, height = 10)
```

```{r}
exQuestion <- reshapedData %>% filter(grepl("Progress", ID))

VoD_log_gmod_easy(exQuestion, "James (Skeptical)", "Ash (Skeptical)")
```

```{r}
# Add direction of update
reshapedData <- reshapedData %>%
    mutate(direction = ifelse(PUc > PU, "up", ifelse(PUc == PU, "no change", "down")))
```

```{r}
# Rank questions by median VoI three ways: all forecasters; skeptic camp only; concerned camp only
central_tendency <- reshapedData %>%
  group_by(ID) %>%
  summarise(q50_KL = quantile(VoI_log, p = 0.5, type = 1, na.rm = TRUE),
            q50_KL_skeptic = quantile(VoI_log[Camp == "Skeptical"], p = 0.5, type = 1, na.rm = TRUE),
            q50_KL_concerned = quantile(VoI_log[Camp == "Concerned"], p = 0.5, type = 1, na.rm = TRUE),
            median_KL = median(VoI_log, na.rm = TRUE),
            median_KL_skeptic = median(VoI_log[Camp == "Skeptical"], na.rm = TRUE),
            median_KL_concerned = median(VoI_log[Camp == "Concerned"], na.rm = TRUE),
            median_naive = median(VoI_naive, na.rm = TRUE),
            median_naive_skeptic = median(VoI_naive[Camp == "Skeptical"], na.rm = TRUE),
            median_naive_concerned = median(VoI_naive[Camp == "Concerned"], na.rm = TRUE))

write.csv(central_tendency, "median_individual_KL_and_naive.csv", row.names = FALSE)
```

```{r}
# Median forecasters - how many times is it zero (just checking)
central_tendency %>% filter(q50_KL_concerned == 0)
```

```{r}
# Who are the median forecasters in each camp for each question? Filter reshapedData to those rows
arj <- merge(central_tendency, reshapedData) %>%
  select(ID, starts_with("q50_KL_"), person, Camp, PU, Pc, PUc, punotc, VoI_log, direction)

# Filter arj to the rows within ID where VoI_log == median_KL_skeptic or median_KL_concerned
arjj <- arj %>%
  group_by(ID) %>%
  filter(VoI_log == q50_KL_skeptic | VoI_log == q50_KL_concerned) %>%
  select(ID, person, Camp, VoI_log, PU, PUc, Pc, punotc) %>%
  filter(VoI_log != 0) %>%
  mutate(VoD_log_gmod = ifelse(n() >= 2, VoD_log_gmod_easy(cur_data(), person[1], person[2]), NA)) %>%
  arrange(VoD_log_gmod, ID)

# How many IDs in arjj have two or more people (VoD should be defined for 19 questions, I think?)
arjj %>% group_by(ID) %>% filter(n() >= 2) %>% summarize(n = n())

VoD_between_medians <- arjj %>%
  select(ID, VoD_log_gmod) %>%
  distinct()
```

```{r}
# AVERAGE RANK METHOD: FOR LOG VOI
# First, rank questions by person. Then take average rank of each question
df <- reshapedData %>%
  group_by(person) %>%
  mutate(rank_KL = rank(-VoI_log, ties.method = "min", na.last = "keep"),
         rank_naive = rank(-VoI_naive, ties.method = "min", na.last = "keep"))

df_skeptic <- reshapedData %>%
  filter(Camp == "Skeptical") %>%
  group_by(person) %>%
  mutate(rank_skeptic_KL = rank(-VoI_log, ties.method = "min", na.last = "keep"),
         rank_skeptic_naive = rank(-VoI_naive, ties.method = "min", na.last = "keep")) %>%
  select(person, ID, rank_skeptic_KL, rank_skeptic_naive)

df_concerned <- reshapedData %>%
  filter(Camp == "Concerned") %>%
  group_by(person) %>%
  mutate(rank_concerned_KL = rank(-VoI_log, ties.method = "min", na.last = "keep"),
         rank_concerned_naive = rank(-VoI_naive, ties.method = "min", na.last = "keep")) %>%
  select(person, ID, rank_concerned_KL, rank_concerned_naive)

df <- merge(df, df_skeptic, by = c("ID", "person"), all.x = TRUE)
df <- merge(df, df_concerned, by = c("ID", "person"), all.x = TRUE)

# Take average rank per question
avg_ranks <- df %>%
  group_by(ID) %>%
  summarize(avg_rank_KL = mean(rank_KL, na.rm = TRUE),
            avg_rank_skeptic_KL = mean(rank_skeptic_KL, na.rm = TRUE),
            avg_rank_concerned_KL = mean(rank_concerned_naive, na.rm = TRUE),
            avg_rank_naive = mean(rank_naive, na.rm = TRUE),
            avg_rank_skeptic_naive = mean(rank_skeptic_naive, na.rm = TRUE),
            avg_rank_concerned_naive = mean(rank_concerned_naive, na.rm = TRUE))

write.csv(avg_ranks, "mean_ranks_KL_and_naive.csv", row.names = FALSE)
```

```{r}
# What's the max VoI_log for just the skeptic camp?
max(reshapedData$VoI_log[reshapedData$Camp == "Skeptical"], na.rm = TRUE)

# Order ID levels by median (or mean)
reshapedData$ID <- factor(reshapedData$ID, levels = central_tendency$ID[order(central_tendency$q50_KL)])

# create the plot
plotMe <- function(reshapedData) {
  ggplot(reshapedData, aes(x = ID, y = VoI_log, color = Camp, shape = direction)) +
    geom_point() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
    scale_y_continuous(trans = log10_trans(),
                      breaks = trans_breaks("log10", function(x) 10^x),
                      labels = trans_format("log10", math_format(10^.x))) +
    geom_point(data = central_tendency, aes(x = ID, y = q50_KL_concerned), color = "#f8a06d", shape = 16, alpha = .3, size = 4, show.legend = FALSE) +
    geom_point(data = central_tendency, aes(x = ID, y = q50_KL_skeptic), color = "#0072c4", shape = 16, alpha = .3, size = 4, show.legend = FALSE) +
    #scale_y_continuous(trans = pseudo_log_trans(sigma = 1, base = 10), limits = c(0, 0.0075)) +
    labs(x = "Question ID", y = "Log VoI", color = "Person", shape = "Direction") +
    scale_shape_manual(values = c("up" = 17, "down" = 25, "no change" = 8)) # 19 and 17 are the shapes for the points
}

plotMe(reshapedData)
ggsave("VoI_log.png", width = 10, height = 8)

# Ordered versions of same
reshapedData$ID <- factor(reshapedData$ID, levels = central_tendency$ID[order(central_tendency$q50_KL_concerned)])

plotMe(reshapedData)
ggsave("VoI_log_ordered_concerned.png", width = 10, height = 9)

reshapedData$ID <- factor(reshapedData$ID, levels = central_tendency$ID[order(central_tendency$q50_KL_skeptic)])

plotMe(reshapedData)
ggsave("VoI_log_ordered_skeptic.png", width = 10, height = 9)
```

```{r}
if (FALSE) {
  CG30a <- reshapedData %>%
      filter(ID == "CG30a") %>%
      select(person, PU, PUc, Pc, punotc)

  people <- unique(cg30a$person)
  numpeople <- length(people)

  # create a symmetric adjacency matrix where each cell is the vod between the two people
  cg30a_vod <- matrix(0, nrow = numpeople, ncol = numpeople)
  rownames(cg30a_vod) <- cg30a$person
  colnames(cg30a_vod) <- cg30a$person

  for (i in 1:(numpeople-1)) {
      for (j in (i+1):numpeople) {
          cg30a_vod[i, j] <- VoD_log_gmod_easy(cg30a, people[i], people[j])
          cg30a_vod[j, i] <- cg30a_vod[i, j]  # use the same value for the 'mirror' cell
      }
  }
}
```

```{r}
# Fiedler ordering & heatmap

# install necessary packages
library(igraph)
library(pheatmap)

make_fiedler_ordered_heatmap <- function(mat, title) {
  #' @param mat a matrix of pairwise VoD for ONE QUESTION

  # NOTE: NOT SURE IF THIS IS THE RIGHT THING TO DO
  mat[is.nan(mat)] <- 0
  mat[is.na(mat)] <- 0

  # create an igraph object
  g <- graph_from_adjacency_matrix(mat, mode = "undirected", weighted = TRUE, diag = FALSE)

  # calculate Laplacian matrix
  laplacian <- laplacian_matrix(g)

  # compute eigenvalues and eigenvectors
  eigen_info <- eigen(laplacian)

  # get the Fiedler vector - the eigenvector of the second smallest eigenvalue
  fiedler_vector <- eigen_info$vectors[,which.min(eigen_info$values[eigen_info$values > min(eigen_info$values)])]

  # create an ordering based on the Fiedler vector
  fiedler_ordering <- order(fiedler_vector)

  # reorder the adjacency matrix
  mat_reordered <- mat[fiedler_ordering, fiedler_ordering]

  # Start png device
  png(paste0("p8_heatmaps/heatmap_anon_", title, ".png"), width = 800, height = 800)

  # create a heatmap
  pheatmap(mat_reordered, main = title)

  # Close device
  dev.off()
}

```

```{r}
# Select the unique reshapedData IDs
uniqueIDs <- unique(reshapedData$ID)

for (question in uniqueIDs) {
  questionData <- reshapedData %>%
    filter(ID == question) %>%
    select(person, PU, PUc, Pc, punotc)
  people <- unique(questionData$person)
  numpeople <- length(people)

  # create a symmetric adjacency matrix where each cell is the vod between the two people
  vod_matrix <- matrix(0, nrow = numpeople, ncol = numpeople)
  rownames(vod_matrix) <- questionData$person
  colnames(vod_matrix) <- questionData$person

  for (i in 1:(numpeople-1)) {
      for (j in (i+1):numpeople) {
          vod_matrix[i, j] <- VoD_log_gmod_easy(questionData, people[i], people[j])
          vod_matrix[j, i] <- vod_matrix[i, j]  # use the same value for the 'mirror' cell
      }
  }

  make_fiedler_ordered_heatmap(vod_matrix, question)
}
```

```{r}
# PAIRWISE LOG gmod VOD

# For each question (ID) in reshapedData, for each pair of people (person), calculate the VoD (log, gmod)

results <- list()

# Split dataframe by ID
split_data <- split(reshapedData, reshapedData$ID)

for (id in unique(reshapedData$ID)) {
  
  dt_subset <- split_data[[as.character(id)]]
  
  # Identify all unique person combinations
  people <- unique(dt_subset$person)
  combinations <- combn(people, 2) # Gets all combinations of people taken 2 at a time
  
  # For each combination, compute the statistic
  for (col in seq(1, ncol(combinations))) {
    id1 <- combinations[1, col]
    id2 <- combinations[2, col]
    
    statistic_value <- VoD_log_gmod_easy(dt_subset, id1, id2)
    
    results[[paste(id, id1, id2, sep = "_")]] <- statistic_value
  }
}

# Convert the list of results to a dataframe if needed
results_df <- data.frame(ID_pair = names(results), value = unlist(results))

# Filter to only the rows that contain (Skeptical) AND (Concerned)
results_df_cross_camp <- results_df %>%
  filter(grepl("Skeptical", ID_pair) & grepl("Concerned", ID_pair))

# Make a column ID that's ID_pair before the underscore
results_df_cross_camp <- results_df_cross_camp %>%
  mutate(ID = gsub("_.*", "", ID_pair))

# Now give me variance of VoD_log_gmod_easy for each question
VoD_variance <- results_df_cross_camp %>%
  group_by(ID) %>%
  summarize(variance = var(value, na.rm = TRUE)) %>%
  arrange(desc(variance))

VoD_quantiles <- results_df_cross_camp %>%
  group_by(ID) %>%
  summarize(median = median(value, na.rm = TRUE),
  # Give me two more columns: 25th quantile and 75th quantile
            quantile_25 = quantile(value, 0.25, na.rm = TRUE),
            quantile_75 = quantile(value, 0.75, na.rm = TRUE)) %>%
  mutate(IQR = quantile_75 - quantile_25,
         platform = grepl("Platform", ID)) %>%
  arrange(desc(median)) %>%
  select(ID, median, quantile_25, quantile_75, IQR, platform)

VoD_quantiles <- merge(VoD_quantiles, VoD_between_medians, by = "ID")

# Make ID a factor, ordered by median
VoD_quantiles$ID <- factor(VoD_quantiles$ID, levels = VoD_quantiles$ID[order(VoD_quantiles$median)])

# Plot VoD_quantiles with x axis is ID (question) and plot box with quantile_25 and quantile_75
ggplot(VoD_quantiles, aes(x = ID, y = median)) +
  geom_boxplot() +
  geom_errorbar(aes(ymin = quantile_25, ymax = quantile_75, color = platform), width = 0.2) +
  labs(x = "Question ID", y = "Log VoD", title = "Log VoD Between Cross-Camp Pairs") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) #+
  # Plot VoD_log_gmod as green stars
  #geom_point(aes(y = VoD_log_gmod, color = 'green'), shape = 8, size = 3, show.legend = FALSE)

ggsave("VoD_log_gmod_easy.png", width = 8, height = 8)
```

```{r}
results_df_cross_camp_f <- results_df_cross_camp %>%
  select(ID, value) %>%
  group_by(ID) %>%
  summarize(median_cross_camp_pairs = quantile(value, type = 1, p = 0.5, na.rm = TRUE))

median_forecasters_f <- arjj %>%
  select(ID, VoD_log_gmod)

compare_VoD <- merge(results_df_cross_camp_f, median_forecasters_f, by = "ID", all.x = TRUE) %>%
  arrange(VoD_log_gmod) %>%
  rename(VoD_between_medians = VoD_log_gmod) %>%
  distinct()

write.csv(compare_VoD, "compare_VoD.csv", row.names = FALSE)
```

```{r}
# Get component-wise VOI for each question
compwise <- reshapedData %>%
  group_by(ID, Camp) %>%
  summarize(median(PU), median(PUc), median(Pc), median(punotc), median(VoI_log, na.rm=TRUE))

cc <- as.data.frame(compwise) %>%
  group_by(ID, Camp) %>%
  mutate(componentWiseVoI = VoI_log(`median(PU)`, `median(PUc)`, `median(Pc)`, `median(punotc)`),
         PUc_x_Pc_less_than_PU = `median(PUc)` * `median(Pc)` < `median(PU)`) %>%
  mutate(punotc_check = punotc(`median(Pc)`, `median(PUc)`, `median(PU)`))

write.csv(cc, "componentwise.csv", row.names = FALSE)
```

```{r}
# Spot-checking VoD on short-term GDP change
gdp <- reshapedData %>% filter(grepl("Short-term", ID))
# VoD ~ 0
xander_v_vincent <- VoD_log_gmod_easy(gdp, "Xander (Concerned)", "Vincent (Concerned)")
# VoD ~ 4
xander_v_quentin <- VoD_log_gmod_easy(gdp, "Xander (Concerned)", "Quentin (Concerned)")
# Very negative VoD
ume_v_hank <- VoD_log_gmod_easy(gdp, "Ume (Concerned)", "Hank (Skeptical)")
ume_v_ash <- VoD_log_gmod_easy(gdp, "Ume (Concerned)", "Ash (Skeptical)")
ume_v_james <- VoD_log_gmod_easy(gdp, "Ume (Concerned)", "James (Skeptical)")
ume_v_claire <- VoD_log_gmod_easy(gdp, "Ume (Concerned)", "Claire (Skeptical)")
```

```{r}
# Group by question, get gmod log VoI for each question
aggVoi <- reshapedData %>%
  group_by(ID) %>%
  summarise(gmod_voi = exp(mean(log(VoI_log), na.rm = TRUE)),
            mean_voi = mean(VoI_log, na.rm = TRUE),
            median_voi = median(VoI_log, na.rm = TRUE))
```

```{r}
# Order ID levels
print(aggVoi %>% arrange(median_voi), n = 40)
```

```{r}
# How many NA's are there in reshapedData$VoI_log? NA's bad, should fix
sum(is.na(reshapedData$VoI_log))
sum(reshapedData$VoI_log == 0)
```

```{r}
# Is it ever the case that PU is zero but PUc is not? That would be inconsistent
reshapedData %>%
  filter(PU == 0 & PUc != 0)
```

```{r}
# Histogram of median log VoI's
ggplot(aggVoi, aes(x = median_voi)) +
  geom_histogram(binwidth = 0.00001) +
  labs(x = "Median log VoI", y = "Count")

ggsave("median_voi_hist.png", width = 10, height = 10)
```

```{r}
# Histogram of mean log VoI's
ggplot(aggVoi, aes(x = mean_voi)) +
  geom_histogram(binwidth = 0.001) +
  labs(x = "Mean log VoI", y = "Count")

ggsave("mean_voi_hist.png", width = 10, height = 10)
```

```{r}
# Create a column in reshapedData that tells me whether >0.67 of the people updated in the same direction, and if so, which
directions <- reshapedData %>%
  group_by(ID, Camp) %>%
  summarize(numUp = sum(direction == "up"), numDown = sum(direction == "down"), total = n()) %>%
  # Determine ***REMOVED*** direction
  mutate(***REMOVED***Direction =
          ifelse(numUp > 0.67 * total, "up",
                 ifelse(numDown > 0.67 * total, "down", "no ***REMOVED***")))

M <- reshapedData %>%
  group_by(ID, Camp) %>%
  summarize(median_KL = median(VoI_log, na.rm = TRUE))

directions2 <- merge(M, directions, by = c("ID", "Camp")) %>%
  arrange(desc(median_KL))
write.csv(directions2, "directions2.csv", row.names = FALSE)

print(directions %>% select(ID, Camp, ***REMOVED***Direction), n = 60)
```

```{r}
library(data.table)
library(reshape2)

prepost <- data.table(
  # Make a dataframe with four columns: Camp, Initial forecast, Final forecast, and Reason for update. Camp is "Concerned" 11 times and "Skeptical" 11 times
  Camp = c(rep("Concerned", 11), rep("Skeptical", 11)),
  ID = 1:22,
  Initial = c(65, 60, 35, 30, 30, 25, 22.9, 21, 10, 9, 4, 3, 1.5, .5, .4, .2, .1, .1, .1, .05, .000001, 0.0000001),
  Final = c(55, 30, NA, NA, NA, 20, 17.5, 18, NA, NA, 2.4, 2, 1, NA, 1.1, .1, .12, .2, .02, .07, .0001, .0001)
)

# reshape prepost so that Initial and Final are in one column, and which is which is denoted by a new column InitFinal
prepostMelt <- melt(prepost, id.vars = c("Camp", "ID"), variable.name = "InitFinal", value.name = "Value")

# Create a custom color palette for IDs
custom_color_palette <- c("#E41A1C", "#377EB8", "#4DAF4A", "#984EA3", "#FF7F00", "#FFFF33", "#A65628", "#F781BF", "#999999", "#FDBF6F", "#CAB2D6", "#6A3D9A", "#FB9A99", "#B15928", "#FDBF6F", "#B3DE69", "#FCCDE5", "#D9D9D9", "#FFFFB3", "#DEB887", "#FFD700", "#FF69B4")

# Create the scatter plot with shapes for "Concerned" vs. "Skeptical" and color for ID
g2 <- ggplot(data = prepost) +
  geom_point(aes(x = "Initial", y = Initial, shape = Camp, color = as.factor(ID)), size = 3, position = position_dodge(width = 0.3), alpha = 0.6) +
  geom_point(aes(x = "Final", y = Final, shape = Camp, color = as.factor(ID)), size = 3, position = position_dodge(width = 0.3), alpha = 0.6) +
  labs(title = "Initial and Final P(doom) Forecasts",
       x = "Forecast Type",
       y = "Values") +
  scale_x_discrete(labels = c("Initial" = "Initial Forecast", "Final" = "Final Forecast")) +
  scale_y_log10() +  # Set y-axis to log scale
  scale_color_manual(values = custom_color_palette) +  # Set the custom color palette
  guides(color = FALSE)  # Remove the legend for ID


ggsave("postpost2.png", g2, width = 6, height = 8)
```

```{r}
# Using prepost, get change in forecast (final - initial) for each ID, plot that
prepost <- prepost %>%
  # If Final is NA, replace it with initial?
  mutate(Final = ifelse(is.na(Final), Initial, Final)) %>%
  mutate(change = Final - Initial)

# Create the scatter plot with shapes for "Concerned" vs. "Skeptical" and color for ID
h <- ggplot(data = prepost) +
  aes(x = Initial, y = change, shape = Camp) +
  geom_point(size = 3, color = "royalblue2", alpha = 0.5) +
  labs(title = "Change in P(doom) Forecasts",
       x = "Initial Forecast",
       y = "Change in Forecast") +
  scale_color_manual(values = custom_color_palette)  # Set the custom color palette

ggsave("change.png", h, width = 6, height = 6)
```

```{r}
# Plot initial (x) vs final (y) forecasts, with shape for Camp
g <- ggplot(data = prepost) +
  aes(x = Initial, y = Final, shape = Camp) +
  geom_point(size = 3, color = "royalblue2", alpha = 0.5) +
  # Make both axes log scale
  scale_x_log10(limits=c(1e-8, 60)) +
  scale_y_log10(limits=c(1e-8, 60)) +
  # Also plot an x = y line, dotted, green
  geom_abline(intercept = 0, slope = 1, linetype = "dotted", color = "green") +
  labs(title = "Initial and Final P(doom) Forecasts",
       x = "Initial Forecast",
       y = "Final Forecast") +
  scale_color_manual(values = custom_color_palette)  # Set the custom color palette

ggsave("prepost_new.png", g, width = 7, height = 6)
```

```{r}
# Plot initial (x) vs final (y) forecasts, with shape for Camp
g <- ggplot(data = prepost) +
  aes(x = Initial, y = Final, shape = Camp) +
  geom_point(size = 3, color = "royalblue2", alpha = 0.5) +
  # Limit both axes to (1, 60)
  coord_cartesian(xlim = c(1, 60), ylim = c(1, 60)) +
  # Also plot an x = y line, dotted, green
  geom_abline(intercept = 0, slope = 1, linetype = "dotted", color = "green") +
  labs(title = "Initial and Final P(doom) Forecasts",
       x = "Initial Forecast",
       y = "Final Forecast") +
  scale_color_manual(values = custom_color_palette)  # Set the custom color palette

ggsave("prepost_new_zoom_2.png", g, width = 7, height = 6)
```

```{r}
dogData <- prepostMelt %>% filter(!is.na(Value))

# Make box and whisker plots with dots for reshapedData$VoI_log by Camp and ID
dog <- ggplot(dogData, aes(x = Camp, y = Value, color = InitFinal)) +
  geom_boxplot() +
  scale_y_log10(limits = c(1e-7, 66)) +
  labs(x = "Question ID", y = "VoI_log", color = "Camp")

ggsave("boxplot.png", dog)

# Calculate boxplot stats to identify outliers
box_stats <- function(x) {
  # Calculate the quartiles and IQR
  quartiles <- quantile(x, probs = c(0.25, 0.75))
  iqr <- diff(quartiles)
  
  # Calculate the whiskers' range
  whiskers <- quartiles + 1.5 * c(-iqr, iqr)
  
  # Identify outliers
  outliers <- x[x < whiskers[1] | x > whiskers[2]]
  
  # Identify median
  median_val <- quantile(x, p = 0.5)
  
  return(data.frame(y = c(outliers, median_val), label = c(outliers, median_val)))
}

# Calculate the medians and outliers
textData <- dogData %>%
  group_by(Camp, InitFinal) %>%
  do(box_stats(.$Value))

library(ggrepel)

dog2 <- dog +
    stat_summary(
      geom = "label",
      data = textData,
      aes(label = Round(..y.., 2)),
      position = position_dodge2(width = 0.75, preserve = "single"),
      vjust = 0.5,
      size = 3,
      fill = "white",
      show.legend = FALSE
    )
  #geom_text_repel(
  #  data = textData,
  #  aes(y = y, label = round(label, 2)),
  #  position = position_dodge2(width = 0.75, preserve = "single"),
  #  vjust = 0.5,
  #  size = 3,
  #  fill = "white",
  # segment.color = 'grey50'
  #)

ggsave("boxplot_labeled.png", dog2)
```

```{r}
# Calculate medians for each group
medians <- dogData %>%
  group_by(Camp, InitFinal) %>%
  summarise(Median = quantile(Value, 0.5, type = 1))

# Create the ggplot
dog <- ggplot(dogData, aes(x = Camp, y = Value, color = InitFinal)) +
  # Box plot without whiskers
  geom_boxplot(outlier.shape = NA, coef = 0) +
  # Add individual points
  geom_point(position = position_jitterdodge(jitter.width = 0.1)) +
  # Log scale
  scale_y_log10(limits = c(1e-7, 66)) +
  # Add labels to the points
  geom_text_repel(
    aes(label = Value),
    box.padding = 0.5,
    point.padding = 0.5,
    position = position_jitterdodge(jitter.width = 0.1),
    max.overlaps = 4
  ) +
  # Add median labels
    geom_text(
    data = medians,
    aes(y = Median, label = round(Median, 2), color = InitFinal),
    vjust = -0.5,
    position = position_dodge(0.6)
  ) +
  # Add labels and themes as you like
  labs(x = "Camp", y = "P(AI Extinction by 2100)", color = "Init/Final")
  # Add labels and themes as you like
  labs(x = "Camp", y = "Value", color = "Init/Final")

ggsave('dflkj.png', dog)
```

```{r}
VoI_log(0.01, 0.0001, 0.08)
VoI_log(0.01, 0.1, 0.08)
```

```{r}
VoI_log(0.01, 0.001, 0.08)
VoI_log(0.01, 0.0001, 0.08)
```

```{r}
ss = "(C2*log(C2/D2)+(1-C2)*log((1-C2)/(1-D2)))*B2 + (E2*log(E2/D2)+(1-E2)*log((1-E2)/(1-D2)))*(1-B2)"

# In that string, replace C2 with PUc, D2 with PU, E2 with punotc, and B2 with Pc
ss = gsub("C2", "PUc", ss)
ss = gsub("D2", "PU", ss)
ss = gsub("E2", "punotc", ss)
ss = gsub("B2", "Pc", ss)

CQ30 = VoI_log(1e-8, 1e-7, 1e-6)
JC50 = VoI_log(1e-8, 4e-8, 1e-6)
LR70 = VoI_log(1e-8, 1e-6, 1e-5)
CQ40 = VoI_log(1e-8, 1e-7, 1e-8)
HN50 = VoI_log(1e-8, 1e-8, 1e-1)
```
